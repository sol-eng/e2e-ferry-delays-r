---
title: "Raw Data Download"
format:
  email:
    table-of-contents: true
    anchor-sections: true
    code-fold: false
    code-overflow: wrap
    code-summary: "Show Code"
    code-tools: true
    code-link: true
editor_options: 
  chunk_output_type: console
  canonical: true
---

```{r}
#| echo: false
gitlink::ribbon_css("https://github.com/sol-eng/e2e-ferry-delays-r.git", text="View on GitHub")
```


## Goals

The goals of this notebook are to:

-   Use `{httr2}` to download the raw Washington State Ferries data and weather data, which is used throughout this project
-   Write the raw data to a database
-   Use a simple threshold alert to trigger a notification email
-   Publish this notebook to Posit Connect and put it on a rendering schedule so database updates happen automatically
-   See some general logging examples that make your scheduled reports more useful

This will give you experience setting up a repeatable workflow for populating production data sources.

## Data sources

We are using data sets from two main sources, with the aim of gathering historical sailings, combining with historical weather, and developing a model to predict whether a future sailing will be delayed.

### From WSDOT Traveler Information API

(<https://wsdot.wa.gov/traffic/api/>)

| Endpoint               | Description                                                                                           | API                                                                                                                                     |
|------------------|-----------------------|--------------------------------|
| **Vessel verbose**     | Reference details about each ferry in the fleet, including name, model, and capacity                  | `https://www.wsdot.wa.gov/ferries/api/vessels/ rest/vesselverbose?apiaccesscode={WSDOT_ACCESS_CODE}`                                    |
| **Vessel history**     | Historical sailings, including scheduled actual departure time                                        | `https://www.wsdot.wa.gov/ferries/api/vessels/ rest/vesselhistory/{VESSELNAME}/{DATESTART}/{DATEEND}?apiaccesscode={WSDOT_ACCESS_CODE}` |
| **Terminal locations** | Terminal names and locations, including latitude and longitude, which we'll need for the weather data | `https://www.wsdot.wa.gov/ferries/api/terminals/ rest/terminallocations?apiaccesscode={WSDOT_ACCESS_CODE}`                              |

### From Open Meteo

([https://open-meteo.com/en/docs/](https://open-meteo.com/en/docs/historical-weather-api/))

| Endpoint               | Description                                                                       | API                                                       |
|------------------|--------------------------------|-----------------------|
| **Historical weather** | Historical hourly weather at a specified latitude and longitude over a date range | `https://archive-api.open-meteo.com/v1/ archive?{params}` |

We will use the `{httr2}` package to download the data from these API sources.

## Load Packages

```{r}
#| label: setup
 
library(httr2)
library(tidyverse)
library(janitor)
library(DBI)
library(odbc)
library(glue)
library(usethis)
library(ferryfairy) #‚õ¥Ô∏è A custom package we wrote that is served by Package Manager

```

## Download vessel verbose data

```{r}
#| label: download raw vessel data
 
base_url <- "https://www.wsdot.wa.gov"

endpoint <- "ferries/api/vessels/rest/vesselverbose"

# Compose the API request 
req <- request(base_url) |> 
  req_url_path_append(endpoint) |> 
  req_url_query(apiaccesscode = Sys.getenv("WSDOT_ACCESS_CODE")) 

# We can inspect the request before performing it
req

# perform the request
response <- req |> 
  req_perform()
response

# convert the body of the response to a tibble
response_body <- response |> 
  resp_body_string() |> 
  jsonlite::fromJSON() |> 
  as_tibble()
response_body

# Sometimes special characters or spaces in column names are not
# database-friendly, so we will use `janitor::clean_names` to
# clean column names so there are no issues writing the data.
# Additionally, the results include a nested dataframe of Class information - 
# we will unnest this so there are no errors with our database interpreting this.
vesselinfo_raw <- response_body |> unnest(Class) |>  clean_names() 
vesselinfo_raw
```

## Connect to the database

```{r}
#| label: make database connection
#| eval: false

# Run this code as-is 
con <- dbConnect(
  odbc::odbc(),
  Driver      = "postgresql",
  Server      = Sys.getenv("DATABASE_HOST"),
  Port        = "5432",
  Database    = Sys.getenv("DATABASE_NAME_R"),
  UID         = Sys.getenv("DATABASE_USER_R"),
  PWD         = Sys.getenv("DATABASE_PASSWORD_R"),
  timeout     = 10
)
con

```

```{r}
#| label: alternative 

library(pins)
board <- board_connect()
```

## Write to the database

Use `dbWriteTable` to write `vesselinfo_raw` into the database

```{r}
#| label: database write
#| eval: false

my_df_name <- "vesselinfo_raw"

DBI::dbWriteTable(conn = con, # the connection
                  name = my_df_name, # the name of the table you will create in the DB
                  value = vesselinfo_raw,
                  overwrite = TRUE)
```

```{r}
board |> pin_write(vesselinfo_raw)
```

## Get and write the other data sets

Now we get the following additional data sets:

-   **Vessel History**: the `https://www.wsdot.wa.gov/Ferries/API/Vessels/rest/vesselhistory` endpoint contains historical data about sailings.

-   **Terminal locations**: the `https://www.wsdot.wa.gov/Ferries/API/terminals/rest/terminallocations` endpoint contains information about ferry terminals locations.

-   **Weather data**: the `https://archive-api.open-meteo.com/v1/archive?{params}` endpoint contains historical hourly weather information for a location and date, including things that may affect the timeliness of our ferry departure, such as wind speed, cloud cover, and precipitation.

### Vessel history

We'll query 30 days looking back from today's date, and use the vessel names we retrieved from the Vessel Verbose endpoint to query the `vesselhistory` endpoint for each vessel name.

Rather than manually repeating the API call for each vessel though, we'll use a function we wrote into the `ferryfairy` package that iterates the API call over the list of vessel names using the same technique as above with `httr2`.

```{r}
#| label: download raw vessel history

# Specify our parameters:
start_date <- today()-30
end_date <- today()
vesselnames <- vesselinfo_raw |> pull(vessel_name)

# Use `ferryfairy::get_vesselhistory` to iterate over all of the vessels. The results will be a list, with each vessel's history as a list item. 
data_list <- map(vesselnames, get_vesselhistory, start_date, end_date)

# Convert the list into a data frame and clean the column names
vesselhistory_raw <- bind_rows(data_list) |> clean_names()
vesselhistory_raw
```

### Terminal locations

Again, to simplify things, we use a function in `ferryfairy` to retrieve latitude and longitudes for each terminal. The function is a wrapper around `httr2`.

```{r}
#| label: download terminal locations data

terminallocations <- ferryfairy::get_terminalinfo()
terminallocations
```

### Weather data

Similar to the approach used for retrieving Vessel History, we use a function in `ferryfairy` to call the weather API and iterate over all of the departing terminal locations.

The weather API allows us to specify the data and format we want in the query. We will include:

-   precipitation (inches)

-   weather code

-   cloud cover at 10 m

-   wind speed at 10 m (as mph)

-   wind gusts at 10 m (as mph)

-   Timezone: US/Pacific

The Open Meteo API is available to use without an API key when used for educational purposes according to their [Terms of Use](https://open-meteo.com/en/terms). As such, queries are limited to less than 10,000 API calls per day, 5,000 per hour and 600 per minute.

```{r}
#| label: download weather data

# Use `purrr::map` to iterate over all of the terminals. The results will be a list, with each terminal as a list item. 
data_list <- map(terminallocations$terminal_name, 
                 ferryfairy::get_terminal_weather_history, 
                 start_date, end_date)

# Convert the list into a data frame and clean the column names
weather_terminal_history_raw <- bind_rows(data_list) 
weather_terminal_history_raw

```

### Write the data to the database

We'll use a helper function from `{ferryfairy}` for brevity. This is a wrapper around `dbWriteTable` and uses the same method we used above in writing `vesselinfo`.

```{r}
#| label: write remaining data to database
#| eval: false

write_df_to_db(vesselhistory_raw, "vesselhistory_raw", con, append = TRUE)

write_df_to_db(terminallocations, "terminallocations", con, overwrite = TRUE)

write_df_to_db(weather_terminal_history_raw, "weather_terminal_history_raw", con, append = TRUE)

# We're done here with the database, so we can close the connection
dbDisconnect(con)

```

```{r}

board |> pin_write(vesselhistory_raw)

board |> pin_write(terminallocations)

board |> pin_write(weather_terminal_history_raw)

```

## Send an email alert if something is fishy üêü

We will publish this document and schedule it to run daily. However, what if there's something wrong with the data? We want to know about it!

Posit Connect has support for sending emails with Quarto: <https://docs.posit.co/connect/user/quarto/#email-customization>.

The email subject and body are enclosed within `:::` divs and we specify that this document should render an email in the Quarto YAML block at the top of the document using `format: email`.

üí° Consider `format: email` as an extension of the more general `format: html`. This means other YAML options pertinent to html outputs like `toc` and `code-fold` can still be used.

-   Assume that if fewer than 10 records are returned from any of the API calls, there's an issue with the upstream data source and we want to receive an email alert about it.
-   Do this by setting `send_email` to `TRUE` within a block called `::: {email-scheduled}`. When the boolean is true, the email will be sent; otherwise, it will be suppressed. See <https://docs.posit.co/connect/user/quarto/#suppressing-email>

### Define conditionality

```{r}
#| label: set conditions for sending email

records_threshold <- 10

if(nrow(vesselinfo_raw) < records_threshold | 
   nrow(vesselhistory_raw) < records_threshold | 
   nrow(terminallocations) < records_threshold | 
   nrow(weather_terminal_history_raw) < records_threshold){
  send_email <- TRUE
} else send_email <- FALSE
```

### Compose email

The email below will send if the alert condition is set.

::: email
::: email-scheduled
```{r}
send_email
```
:::

::: subject
‚ö†Ô∏è Ferry Project: There was an issue with the raw data.
:::

Fewer rows of raw data were retrieved than expected. The number of records are:

- `r nrow(vesselinfo_raw)` rows of raw vessel data
- `r nrow(vesselhistory_raw)` rows of raw vessel history
- `r nrow(terminallocations)` terminal location records
- `r nrow(weather_terminal_history_raw)` rows of weather data

A minimum of `r records_threshold` records are expected from each source. Please review the source data.

:::

## Add logging information to make our scheduled report informative

üí° Make your scheduled reports work harder for you! Include information that you'll find useful to refer back to. Logging can be as basic or elaborate as you need.

Lets include:

-   A nicely formatted time stamp.

-   A summary the main actions taken in the report, such as how many rows of data were downloaded, how many rows of data were written to the database

Hint: The `glue` package is helpful for combining text and variables. It's less work than stringing things together with `paste`. With `glue::glue()`, the syntax is `glue("Text with {<r expression or variable>}")`

```{r}
#| label: logging

stamp <- format(as.POSIXct(Sys.time(),tz="US/Pacific"),'%A, %B %d, %Y %H:%M:%S')
glue("Report run {stamp}")

glue("Wrote the following to the database: 
     
     {nrow(vesselinfo_raw)} rows of raw vessel data
     {nrow(vesselhistory_raw)} rows of raw vessel history
     {nrow(terminallocations)} terminal location records
     {nrow(weather_terminal_history_raw)} rows of weather data")

```

