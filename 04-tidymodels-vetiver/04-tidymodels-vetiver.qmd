---
title: "Tidymodels and Vetiver"
format: html
editor_options: 
  chunk_output_type: console
  canonical: true
---

## Goals

The goals of this notebook are to:

-   Create two models using the `tidymodels` framework that predict if a Seattle Ferry will depart on time or be delayed from a specific station.
-   Save a model as a pin to Posit Connect using the `vetiver` package.
-   Deploy a model to Posit Connect as an API using the `vetiver` package.
-   Learn how to version and monitor your machine-learning models using `vetiver`.

## Overview

1.  Import validated ferry-weather dataset from the database.
2.  Transform the data for modeling.
3.  Create `logistic_reg()` and `xgboost()` classification models using `tidymodels`.
4.  Assess the performance of both models using `tidymodels`.
5.  Save each model as a pin to Posit Connect using the `vetiver` package.
6.  Use the pinned models to serve a plumber API hosted on Posit Connect.
7.  Use the `vetiver` and `pins` package to version and monitor the performance of the models over time.

## Create a tidymodel

```{r}
#| label: setup
#| warning: false
#| message: false

library(tidyverse)
library(pins)
library(tidymodels)
library(lubridate)
library(skimr)
library(vetiver)
library(xgboost)
library(plumber)
library(rsconnect)
library(odbc)
library(DBI)
library(usethis)
```

For this task, we will train and fit a logistic regression model to predict whether a Seattle Ferry departs a station on time or is delayed.

### Read the `ferry-weather` dataset

```{r}
#| label: read-data
#| eval: false

# Read in dataset from database
df_name <- "modeldata_validated"

con <- dbConnect(
  odbc::odbc(),
  Driver      = "postgresql",
  Server      = Sys.getenv("DATABASE_HOST"),
  Port        = "5432",
  Database    = Sys.getenv("DATABASE_NAME_R"),
  UID         = Sys.getenv("DATABASE_USER_R"),
  PWD         = Sys.getenv("DATABASE_PASSWORD_R"),
  timeout     = 10
)

ferry_weather <- dplyr::tbl(con, df_name) |> 
  collect()

```

```{r}
library(pins)

board <- board_connect()

ferry_weather <- board |> pin_read("katie.masiello@posit.co/modeldata_validated")
```


### Prep Data for Modeling

```{r}
#| label: prep-data

ferry_weather_prepped <- ferry_weather |> 
  
  # Select for columns of interest
  #  Removed vessel but kept departing, since this would cause a rank
  #  deficient fit (all vessels don't depart from all places)
  select(departing, 
         closest_hour, 
         date, 
         weather_code, 
         wind_speed_10m, 
         wind_gusts_10m, 
         delay) |> 
  
  # Convert delay to classification
  #  If more than 3 minutes late --> "delayed"
  mutate(delay_status = case_when(
    delay <= 3 ~ "on-time",
    delay > 3 ~ "delayed" 
  )) |> 
  
  # Convert wind to classification
  #  If more than 10mph --> "windy"
  mutate(wind_status = case_when(
    wind_speed_10m >= 10 ~ "windy",
    wind_speed_10m < 10 ~ "calm"
  )) |> 
  select(-wind_speed_10m) |> 
  
  # Convert gust to classification
  #  If more than 15mph --> "gusty"
  mutate(gust_status = case_when(
    wind_gusts_10m >= 15 ~ "gusty",
    wind_gusts_10m < 15 ~ "calm"
  )) |> 
  select(-wind_gusts_10m) |>
  
  # Convert dates to ymd
  mutate(date = ymd(date)) |>
  
  # Extract closest hour (just the hour)
  mutate(closest_hour = ymd_hms(closest_hour, truncated = 3)) |> 
  mutate(hour = as.factor(hour(closest_hour))) |> 
  select(-closest_hour) |> 
  
  # Change weather code to factor
  mutate(weather_code = as.factor(weather_code)) |> 
  
  # Convert chr to factors
  mutate_if(is.character, as.factor) |> 
  
  # Exclude missing data
  na.omit() |> 
  
  # Clean departing column
  mutate(departing = str_to_title(str_replace_all(departing, "_", " ")))

```


### Split Data

For modeling, you often split your data into a **training and testing** dataset. Before we do that, we'll first extract the last 500 rows, which will be used later on for model monitoring.

```{r}
#| label: split-data

# Monitoring data (will be used later on)
monitoring_data <- tail(ferry_weather_prepped, 500)

# Put 3/4 of the data into the training set 
data_split <- initial_split(head(ferry_weather_prepped, -500), prop = 3/4)

# Create data frames for the two sets:
train_data <- training(data_split)
test_data  <- testing(data_split)
```

### Create the Recipe

```{r}
#| label: create-recipe

ferry_rec <- 
  
  # Add recipe (what does the model do?)
  recipe(delay_status ~ ., data = train_data) |> 
  
  # Remove delay from modeling
  step_rm(delay) |> 
  
  # Extract predictors like day of week and month from date
  step_date(date, features = c("dow", "month"), keep_original_cols = FALSE) |> 
  
  # Convert all factors to binary "dummy variables"
  step_dummy(all_nominal_predictors())
```

### Define Model Type

We'll first use logistic regression via *generalized linear model*, or glm. This method is used for predicting binary outcomes (delayed vs on-time).

```{r}
#| label: define-model-type

# Specify model using parsnip
ferry_mod_lr <- 
  logistic_reg() |> 
  set_engine("glm")

```

### Create the Workflow

```{r}
#| label: define-workflow

# Bundle parsnip model with recipe
ferry_workflow_lr <- 
  workflow() |> 
  add_model(ferry_mod_lr) |> 
  add_recipe(ferry_rec)
```

### Train the Model

Train the model using our training set. This step may take a few seconds.

```{r}
#| label: train-model

# Train the model
ferry_fit_lr <- 
  ferry_workflow_lr |> 
  fit(data = train_data)
```

### Evaluate the Model

We'll use `tidymodels` to evaluate how our model did using the testing dataset. Remember that this model is **far from perfect** and we don't care too much about making a perfect model.

```{r}
#| label: evaluate-model

# Make Prediction
predictions_lr <- augment(ferry_fit_lr, test_data)

# Evaluate the model
metrics_lr <- predictions_lr |> 
  metrics(truth = delay_status, estimate = .pred_class)

metrics_lr

# Confusion Matrix
predictions_lr |> 
  conf_mat(delay_status, .pred_class)

```


## Pin Model to Posit Connect

Now that we have a model, we'll want to save it to a location so that it can be easily shared with colleagues, other content, or your future self! The `pins` package is the workhorse behind this workflow. The `vetiver` package has some wrappers around the pinning functions that we'll use in this task.

### Create a Vetiver Model and Pin to Posit Connect

Before we go any further, we need to convert our logistic regression model into a format that can be used by `vetiver`:

```{r}
#| label: create-vetiver-model

# Create Vetiver Model
v_model <- vetiver_model(ferry_fit_lr, "katie.masiello@posit.co/ferry_model")

```

And now we can save it, or *pin it*, to Posit Connect! Remember to define your pinning board as Posit Connect.

```{r}
#| label: pin-model

# Register Posit Connect as board
board <- board_connect()

# Write Vetiver Model

board |> vetiver_pin_write(v_model)

```


## Serve Model as an API

```{r}
#| label: create-api
#| message: false

# Create API from pinned model using vetiver
vetiver_deploy_rsconnect(board = board, name = "katie.masiello@posit.co/ferry_model")

```

Once it's deployed, navigate to the API on Posit Connect and give it a test run! Click the operation on the left called `Return predictions from model using 7 features`. Then copy any variation of the request below and click **Try**. You should see a response of either `delayed` or `on-time`.

```         
[
  {
    "departing": "Anacortes",
    "date": "2024-07-05",
    "weather_code": "3",
    "delay": 0,
    "wind_status": "windy",
    "gust_status": "calm",
    "hour": "5"
  }
]
```

### Make a Prediction using R Code

On Posit Connect, navigate to your newly created API, and copy the URL for the content below. You can find this URL by clicking the access tab --\> URL.

```{r}
api_url <- "https://pub.current.posit.team/public/ferry_model"

# Append "/predict" to the end of your api to create the endpoint
endpoint <- vetiver_endpoint(paste0(api_url, "/predict"))

endpoint
```

Below is a data frame representing information on a ferry departing. Let's see if it is predicted to be delayed or ontime. Feel free to modify.

```{r}
#| label: make-new-ferry-data

# Create new ferry data point
new_ferry <- tibble(
  departing = "Friday Harbor",
  date = "2024-07-12",
  weather_code = "3",
  delay = 0,# This feature is not considered by the model
  wind_status = "calm",
  gust_status = "calm",
  hour = "6"
)

```

Now we can use the `predict()` function to query the API so that it returns a prediction of delay or on-time. Note that we have to add our API key to the predict function since this API is only accessible to specific users!

```{r}
#| label: predict-r

# Predict from Vetiver endpoint
predict(endpoint, 
        new_ferry,
        httr::add_headers(Authorization = paste("Key", Sys.getenv("CONNECT_API_KEY"))))$.pred_class
```


## Version and Monitor Model

Creating a model is an iterative process, and chances are you'll create multiple versions of your model along the way. You may even create a completely different model to address the same question. How then can you keep track of all these versions, and ensure that you're always using the best model for the job? Vetiver to the rescue 🦸!

Monitoring a model means you are assessing performance as new data comes in over time. During task 1, we pulled out the bottom 500 rows from our dataset, and saved it to the `monitoring_data` variable. This will simulate the "new" data for model monitoring!

### List Model Versions


```{r}
#| label: list-pin-versions

# View versions of your model 
pin_versions(board = board, name = "katie.masiello@posit.co/ferry_model")

# We can also extract some metadata from the pin
pin_meta(board = board, name = "katie.masiello@posit.co/ferry_model")$description
```

### Create an Xgboost Model

Let's create an xgboost model to answer the same question as our logistic regression model: can we predict if a ferry will be delayed or not. The below code cell will create, train, and assess the performance of our xgboost model. This step will also take a few seconds to run.

```{r}
#| label: create-xgboost-model

# Specify model using parsnip
ferry_mod_xgb <- 
  boost_tree() |> 
  set_engine("xgboost") |> 
  set_mode("classification")

# Bundle parsnip model with recipe
ferry_workflow_xgb <- 
  workflow() |> 
  add_model(ferry_mod_xgb) |> 
  add_recipe(ferry_rec)

# Train the model
ferry_fit_xgb <- 
  ferry_workflow_xgb |> 
  fit(data = train_data)

# Make Prediction
predictions_xgb <- augment(ferry_fit_xgb, test_data)

# Evaluate the model
metrics_xgb <- predictions_xgb |> 
  metrics(truth = delay_status, estimate = .pred_class)

metrics_xgb

# Confusion Matrix
predictions_xgb |> 
  conf_mat(delay_status, .pred_class)

```

### Pin Xgboost Model to Posit Connect

Now that we have created an xgboost model, let's convert it to a `vetiver` model and pin it to the same location as our original **ferry_model** pin. Then we'll check the pin versions again.

```{r}
#| label: pin-xgboost

# Create Vetiver Model
v_model_xgb <- vetiver_model(ferry_fit_xgb, "katie.masiello@posit.co/ferry_model")

# Write Vetiver Model
board |> 
  vetiver_pin_write(v_model_xgb)

# View versions of your model 
pin_versions(board = board, name = "katie.masiello@posit.co/ferry_model")

pin_meta(board = board, name = "katie.masiello@posit.co/ferry_model")$description

```

### Monitor Model Performance

How do we know which model is performing better? Logistic regression or xgboost? That's where model monitoring comes into play. Let's use some common classification model metrics (accuracy and kap) to assess each model using the "new" `monitoring_data`.

❗Be sure add in the version number as a string (eg. "557741").

```{r}
#| label: model-monitoring

# First Model ##############################
pin_version <- "147"

# Pull in specific version of model
v_model_monitor <- vetiver_pin_read(board, "katie.masiello@posit.co/ferry_model", version = pin_version)

new_ferry_data_metrics <-
    augment(v_model_monitor, new_data = arrange(monitoring_data, date)) |> 
    vetiver_compute_metrics(date, "day", delay_status, .pred_class)

vetiver_plot_metrics(new_ferry_data_metrics) +
  scale_size(range = c(2, 4)) +
  ylim(0, 1) +
  labs(title = pin_meta(board = board, "katie.masiello@posit.co/ferry_model", version = pin_version)$description)


# Second Model ##############################
pin_version <- "141"

# Pull in specific version of model
v_model_monitor <- vetiver_pin_read(board, "katie.masiello@posit.co/ferry_model", version = pin_version)

new_ferry_data_metrics <-
    augment(v_model_monitor, new_data = arrange(monitoring_data, date)) |> 
    vetiver_compute_metrics(date, "day", delay_status, .pred_class)

vetiver_plot_metrics(new_ferry_data_metrics) +
  scale_size(range = c(2, 4)) +
  ylim(0, 1) +
  labs(title = pin_meta(board = board, "katie.masiello@posit.co/ferry_model", version = pin_version)$description)
```
