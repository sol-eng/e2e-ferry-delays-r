---
title: "Tidymodels and Vetiver"
format: html
editor_options: 
  chunk_output_type: console
  canonical: true
---

## Goals

The goals of this activity are to:

-   Create two models using the `tidymodels` framework that predict if a Seattle Ferry will depart on time or be delayed from a specific station.
-   Save a model as a pin to Posit Connect using the `vetiver` package.
-   Deploy a model to Posit Connect as an API using the `vetiver` package.
-   Learn how to version and monitor your machine-learning models using `vetiver`.

## Overview

1.  Import validated ferry-weather dataset from the database.
2.  Transform the data for modeling.
3.  Create `logistic_reg()` and `xgboost()` classification models using `tidymodels`.
4.  Assess the performance of both models using `tidymodels`.
5.  Save each model as a pin to Posit Connect using the `vetiver` package.
6.  Use the pinned models to serve a plumber API hosted on Posit Connect.
7.  Use the `vetiver` and `pins` package to version and monitor the performance of the models over time.

## Task 0 - Create and Save a Posit Connect API Key

Before starting this activity, we need to create and save a Posit Connect API key in our environment. This API key identifies you to Connect, allowing you to publish or interact with privileged content if you have the necessary permissions. **YOU SHOULD NEVER ADD YOUR API KEY TO YOUR SOURCE CODE!!!** An API key is like a password, and you should take the necessary steps to secure it. One of those methods is by adding it as an environment variable. You can do this by adding the variable/API key to your `.Renviron` file. This file is interpreted by R every time you start a new session. The `usethis` R packabe makes it super easy to add environment variables.

```{r}
#| eval: false

# Open your .Renviron file
usethis::edit_r_environ()
```

Once you run the above command, you should see a new file open up in RStudio. This is your `.Renviron` file and is usually located in your home (\~) directory. Before we set the variable, we first need to obtain an API key from Connect. Follow the steps below:

1.  Navigate to Posit Connect (https://pub.ferryland.posit.team).
2.  Click your username in the top right corner.
3.  Select **API Keys**
4.  Select **+New API Key**
5.  Name it whatever you like. `Connect-API-Key` is a good option.
6.  Copy the new API key. **DON'T LOSE IT!** If you do lose it, you can create another one.

Navigate back to your `.Renviron` file and add the following line. It's always a good idea to add an additional blank line at the end of your `.Renviron` file. Let's also add the CONNECT_SERVER URL just for good measure!

```         
CONNECT_API_KEY=paste-your-api-key-here
CONNECT_SERVER=https://pub.ferryland.posit.team
```

Now you can close the `.Renviron` file and restart your R session (Session–\>Restart R) so that the API key varialble get's added to our environment. To confirm it worked, try running the following code:

```{r}

# Check if CONNECT_API_KEY is added to environment
Sys.getenv("CONNECT_API_KEY")

# Check if CONNECT_SERVER is added to environment
Sys.getenv("CONNECT_SERVER")
```

You should see the API key in the console. If not, please raise your hand and we'll be around to help you out!

## Task 1 - Create a tidymodel

```{r}
#| label: setup

library(tidyverse)
library(pins)
library(tidymodels)
library(lubridate)
library(skimr)
library(vetiver)
library(xgboost)
library(plumber)
library(rsconnect)
library(odbc)
library(DBI)
library(usethis)
```

[Tidymodels](https://www.tidymodels.org/) is a collection of R packages for modeling and machine learning using [tidyverse](https://www.tidyverse.org/) principles. While this workshop is **not** a modeling workshop, to demonstrate the utility of the `vetiver`, we need to create a model.

For this activity, we will train and fit a logistic regression model to predict whether a Seattle Ferry departs a station on time or is delayed. Later on, we will create another model using xgboost.

🔄 Tasks

-   Explore the `ferry-weather` dataset. Use any method you'd like to understand the data. Try functions like `glimpse()`, `str()`, and `View()`.

-   Create a logistic regression tidymodel that predicts `delay_status`.

#### Read and Explore the `ferry-weather` dataset

```{r}
#| label: read-data
#| eval: false

# Read in dataset from database
df_name <- "modeldata_validated"

con <- dbConnect(
  odbc::odbc(),
  Driver      = "postgresql",
  Server      = Sys.getenv("DATABASE_HOST"),
  Port        = "5432",
  Database    = Sys.getenv("DATABASE_NAME_R"),
  UID         = Sys.getenv("DATABASE_USER_R"),
  PWD         = Sys.getenv("DATABASE_PASSWORD_R"),
  timeout     = 10
)

ferry_weather <- dplyr::tbl(con, df_name) |> 
  collect()

```

```{r}
library(pins)

board <- board_connect()

ferry_weather <- board |> pin_read("katie.masiello@posit.co/modeldata_validated")
```


```{r}
#| label: explore-data

# Use the space below to explore the ferry-weather dataset
# Try functions like glimpse(), str(), skim(), and View()

glimpse(ferry_weather)
str(ferry_weather)
skim(ferry_weather)
View(ferry_weather)

```

#### Prep Data for Modeling

Sometimes, you may need to transform the original dataset to make it conducive to modeling. In the below code cell, read the comment above each bit of code to understand what types of transformations were conducted.

```{r}
#| label: prep-data

ferry_weather_prepped <- ferry_weather |> 
  
  # Select for columns of interest
  #  Removed vessel but kept departing, since this would cause a rank
  #  deficient fit (all vessels don't depart from all places)
  select(departing, 
         closest_hour, 
         date, 
         weather_code, 
         wind_speed_10m, 
         wind_gusts_10m, 
         delay) |> 
  
  # Convert delay to classification
  #  If more than 3 minutes late --> "delayed"
  mutate(delay_status = case_when(
    delay <= 3 ~ "on-time",
    delay > 3 ~ "delayed" 
  )) |> 
  
  # Convert wind to classification
  #  If more than 10mph --> "windy"
  mutate(wind_status = case_when(
    wind_speed_10m >= 10 ~ "windy",
    wind_speed_10m < 10 ~ "calm"
  )) |> 
  select(-wind_speed_10m) |> 
  
  # Convert gust to classification
  #  If more than 15mph --> "gusty"
  mutate(gust_status = case_when(
    wind_gusts_10m >= 15 ~ "gusty",
    wind_gusts_10m < 15 ~ "calm"
  )) |> 
  select(-wind_gusts_10m) |>
  
  # Convert dates to ymd
  mutate(date = ymd(date)) |>
  
  # Extract closest hour (just the hour)
  mutate(closest_hour = ymd_hms(closest_hour, truncated = 3)) |> 
  mutate(hour = as.factor(hour(closest_hour))) |> 
  select(-closest_hour) |> 
  
  # Change weather code to factor
  mutate(weather_code = as.factor(weather_code)) |> 
  
  # Convert chr to factors
  mutate_if(is.character, as.factor) |> 
  
  # Exclude missing data
  na.omit() |> 
  
  # Clean departing column
  mutate(departing = str_to_title(str_replace_all(departing, "_", " ")))

```

Feel free to explore the prepped dataset!

#### Split Data

For modeling, you often split your data into a **training and testing** dataset. Before we do that, we'll first extract the last 500 rows, which will be used later on for model monitoring.

```{r}
#| label: split-data

# Monitoring data (will be used later on)
monitoring_data <- tail(ferry_weather_prepped, 500)

# Put 3/4 of the data into the training set 
data_split <- initial_split(head(ferry_weather_prepped, -500), prop = 3/4)

# Create data frames for the two sets:
train_data <- training(data_split)
test_data  <- testing(data_split)
```

#### Create the Recipe

```{r}
#| label: create-recipe

ferry_rec <- 
  
  # Add recipe (what does the model do?)
  recipe(delay_status ~ ., data = train_data) |> 
  
  # Remove delay from modeling
  step_rm(delay) |> 
  
  # Extract predictors like day of week and month from date
  step_date(date, features = c("dow", "month"), keep_original_cols = FALSE) |> 
  
  # Convert all factors to binary "dummy variables"
  step_dummy(all_nominal_predictors())
```

#### Define Model Type

We'll first use logistic regression via *generalized linear model*, or glm. This method is used for predicting binary outcomes (delayed vs on-time).

```{r}
#| label: define-model-type

# Specify model using parsnip
ferry_mod_lr <- 
  logistic_reg() |> 
  set_engine("glm")

```

#### Create the Workflow

```{r}
#| label: define-workflow

# Bundle parsnip model with recipe
ferry_workflow_lr <- 
  workflow() |> 
  add_model(ferry_mod_lr) |> 
  add_recipe(ferry_rec)
```

### Train the Model

Train the model using our training set. This step may take a few seconds.

```{r}
#| label: train-model

# Train the model
ferry_fit_lr <- 
  ferry_workflow_lr |> 
  fit(data = train_data)
```

#### Evaluate the Model

We'll use `tidymodels` to evaluate how our model did using the testing dataset. Remember that this model is **far from perfect** and we don't care too much about making a perfect model.

```{r}
#| label: evaluate-model

# Make Prediction
predictions_lr <- augment(ferry_fit_lr, test_data)

# Evaluate the model
metrics_lr <- predictions_lr |> 
  metrics(truth = delay_status, estimate = .pred_class)

metrics_lr

# Confusion Matrix
predictions_lr |> 
  conf_mat(delay_status, .pred_class)

```

🛑 Stop here!

## Task 2 - Pin Model to Posit Connect

Now that we have a model, we'll want to save it to a location so that it can be easily shared with colleagues, other content, or your future self! The `pins` package is the workhorse behind this workflow. The `vetiver` package has some wrappers around the pinning functions that we'll use in this task.

🔄 Tasks

-   Create a vetiver model.

-   Pin vetiver model to Posit Connect.

#### Create a Vetiver Model and Pin to Posit Connect

Before we go any further, we need to convert our logistic regression model into a format that can be used by `vetiver`:

```{r}
#| label: create-vetiver-model

# Create Vetiver Model
v_model <- vetiver_model(ferry_fit_lr, "katie.masiello@posit.co/ferry_model")

```

And now we can save it, or *pin it*, to Posit Connect! Remember to define your pinning board as Posit Connect.

```{r}
#| label: pin-model

# Register Posit Connect as board
board <- board_connect()

# Write Vetiver Model

board |> vetiver_pin_write(v_model)

```

Navigate to Posit Connect and check out your pinned model! You'll also notice a message asking you to create a **Model Card**. This is alsways a good idea, especially if you will be sharing your model with others. An example model card can be found here: `materials/04-tidymodels-vetiver/ferry_modelcard_r.Rmd`.

🛑 Stop here!

## Task 3 - Serve Model as an API

APIs are a great way for users, applications, or other systems to interact with your model. `vetiver` leverages [Plumber](https://www.rplumber.io/) which is used to create APIs with only R code! Let's create an API here within Posit Workbench, and then deploy it to Posit Connect.

🔄 Tasks

-   Deploy model to Posit Connect as an API.

-   Make a prediction using the API visual interface (RapiDoc).

-   Make a request to the API using R code.

#### Deploy API to Posit Connect

**Be sure to add your user name for the pin!**

```{r}
#| label: create-api

# Create API from pinned model using vetiver
#  Swap out "____" for your username on Connect.
vetiver_deploy_rsconnect(board = board, name = "katie.masiello@posit.co/ferry_model")

```

Once it's deployed, navigate to the API on Posit Connect and give it a test run! Click the operation on the left called `Return predictions from model using 7 features`. Then copy any variation of the request below and click **Try**. You should see a response of either `delayed` or `on-time`.

```         
[
  {
    "departing": "Anacortes",
    "date": "2024-07-05",
    "weather_code": "3",
    "delay": 0,
    "wind_status": "windy",
    "gust_status": "calm",
    "hour": "5"
  }
]
```

#### Make a Prediction using R Code

On Posit Connect, navigate to your newly created API, and copy the URL for the content below. You can find this URL by clicking the access tab --\> URL.

```{r}
api_url <- "https://pub.current.posit.team/ferry_model"

# Append "/predict" to the end of your api to create the endpoint
endpoint <- vetiver_endpoint(paste0(api_url, "/predict"))

endpoint
```

Below is a data frame representing information on a ferry departing. Let's see if it is predicted to be delayed or ontime. Feel free to modify.

```{r}
#| label: make-new-ferry-data

# Create new ferry data point
new_ferry <- tibble(
  departing = "Friday Harbor",
  date = "2024-07-12",
  weather_code = "3",
  delay = 0,# This feature is not considered by the model
  wind_status = "calm",
  gust_status = "calm",
  hour = "6"
)

```

Now we can use the `predict()` function to query the API so that it returns a prediction of delay or on-time. Note that we have to add our API key to the predict function since this API is only accessible to specific users!

```{r}
#| label: predict-r

# Predict from Vetiver endpoint
predict(endpoint, 
        new_ferry,
        httr::add_headers(Authorization = paste("Key", Sys.getenv("CONNECT_API_KEY"))))$.pred_class
```

🛑 Stop here!

## Task 4 - Version and Monitor Model

Creating a model is an iterative process, and chances are you'll create multiple versions of your model along the way. You may even create a completely different model to address the same question. How then can you keep track of all these versions, and ensure that you're always using the best model for the job? Vetiver to the rescue 🦸!

Before we get started, we first need to make sure that the board we are using to pin our models can accommodate versioning. Fortunately, most boards, including Posit Connect, leverage versioning by default. If you want to explicitly turn on versions, just make sure you use the `versioned` argument when defining your board: `board_connect(versioned = TRUE)`.

Monitoring a model means you are assessing performance as new data comes in over time. During task 1, we pulled out the bottom 500 rows from our dataset, and saved it to the `monitoring_data` variable. This will simulate the "new" data for model monitoring!

🔄 Tasks

-   List model versions.

-   Monitor model performance using *new* ferry data.

#### List Model Versions

We only have 1 version of our model, but let's list it anyway by using the `pin_versions()` function. Take note of the **version number (first column)!**

```{r}
#| label: list-pin-versions

# View versions of your model 
#  Replace "____" with your username 
pin_versions(board = board, name = "katie.masiello@posit.co/ferry_model")

# We can also extract some metadata from the pin
pin_meta(board = board, name = "katie.masiello@posit.co/ferry_model")$description
```

#### Create an Xgboost Model

Let's create an xgboost model to answer the same question as our logistic regression model: can we predict if a ferry will be delayed or not. The below code cell will create, train, and assess the performance of our xgboost model. This step will also take a few seconds to run.

```{r}
#| label: create-xgboost-model

# Specify model using parsnip
ferry_mod_xgb <- 
  boost_tree() |> 
  set_engine("xgboost") |> 
  set_mode("classification")

# Bundle parsnip model with recipe
ferry_workflow_xgb <- 
  workflow() |> 
  add_model(ferry_mod_xgb) |> 
  add_recipe(ferry_rec)

# Train the model
ferry_fit_xgb <- 
  ferry_workflow_xgb |> 
  fit(data = train_data)

# Make Prediction
predictions_xgb <- augment(ferry_fit_xgb, test_data)

# Evaluate the model
metrics_xgb <- predictions_xgb |> 
  metrics(truth = delay_status, estimate = .pred_class)

metrics_xgb

# Confusion Matrix
predictions_xgb |> 
  conf_mat(delay_status, .pred_class)

```

#### Pin Xgboost Model to Posit Connect

Now that we have created an xgboost model, let's convert it to a `vetiver` model and pin it to the same location as our original **ferry_model** pin. Then we'll check the pin versions again.

```{r}
#| label: pin-xgboost

# Create Vetiver Model
v_model_xgb <- vetiver_model(ferry_fit_xgb, "katie.masiello@posit.co/ferry_model")

# Write Vetiver Model
board |> 
  vetiver_pin_write(v_model_xgb)

# View versions of your model 
#  Replace "_____" with your username 
pin_versions(board = board, name = "katie.masiello@posit.co/ferry_model")

pin_meta(board = board, name = "katie.masiello@posit.co/ferry_model")$description

```

#### Monitor Model Performance

How do we know which model is performing better? Logistic regression or xgboost? That's where model monitoring comes into play. Let's use some common classification model metrics (accuracy and kap) to asses each model using the "new" `monitoring_data`.

❗Be sure add in the version number as a string (eg. "557741").

```{r}
#| label: model-monitoring

# First Model ##############################
pin_version <- "147"

# Pull in specific version of model
v_model_monitor <- vetiver_pin_read(board, "katie.masiello@posit.co/ferry_model", version = pin_version)

new_ferry_data_metrics <-
    augment(v_model_monitor, new_data = arrange(monitoring_data, date)) |> 
    vetiver_compute_metrics(date, "day", delay_status, .pred_class)

vetiver_plot_metrics(new_ferry_data_metrics) +
  scale_size(range = c(2, 4)) +
  ylim(0, 1) +
  labs(title = pin_meta(board = board, "katie.masiello@posit.co/ferry_model", version = pin_version)$description)


# Second Model ##############################
pin_version <- "141"

# Pull in specific version of model
v_model_monitor <- vetiver_pin_read(board, "katie.masiello@posit.co/ferry_model", version = pin_version)

new_ferry_data_metrics <-
    augment(v_model_monitor, new_data = arrange(monitoring_data, date)) |> 
    vetiver_compute_metrics(date, "day", delay_status, .pred_class)

vetiver_plot_metrics(new_ferry_data_metrics) +
  scale_size(range = c(2, 4)) +
  ylim(0, 1) +
  labs(title = pin_meta(board = board, "katie.masiello@posit.co/ferry_model", version = pin_version)$description)
```
